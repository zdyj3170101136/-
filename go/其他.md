```
var _ datastore.Datastore = (*Datastore)(nil)
```





生产者消费者模型。

主线程生产要处理的函数，并发的协程从chan里头读取要处理的值。

发送完了之后关闭chan，通知对方waitgroup done然后返回。

注意传递waitgroup的指针。

for循环遍历chan可以当关闭之后自动退出。

```
wg := sync.WaitGroup{}

writeState.start = time.Now()

for i := 0; i < b.concurrency; i++ {
   wg.Add(1)
   go writefile(&wg, filenameChan, &writeState.localStat[i])
}

for _, fileInfo := range fileInfos {
   filenameChan <- fileInfo
}

close(filenameChan)

wg.Wait()

```

```
func writefile(wg *sync.WaitGroup, filenameChan chan os.FileInfo, localState *stat) {
   defer wg.Done()

   url := fmt.Sprintf(
      "http://%s/op/add?namespace=%s&%s=%d",
      b.url,
      DefaultNamespace,
      http.KeyBackNum,
      b.backnum,
   )

   for fstat := range filenameChan {
```

但是当我们不仅要检查任务是否完成，同时还需要检查程序本身有没有关闭。

我们会使用select读取值，如果返回的是true表示还有值。

而如果返回不是说明已经关闭了这个chan，这个时候return。

waitgroup用来等待关闭所有的并发chan之后再完成。



而还有一个context，用来关闭这个程序。

更具体的说我们会子协程通常使用context监听上层服务的关闭select。

而通常我们会用一个context开启多个协程。

waitgroup保证协程关闭。

context保证更底层的关闭。而context往往使用之前的context创造。



先wa.wait再cancel。

```
findProviderCtx, cancel := context.WithTimeout(fpr.ctx, pqm.findProviderTimeout)
pqm.timeoutMutex.RUnlock()
providers := pqm.network.FindProvidersAsync(findProviderCtx, k, maxProviders)
wg := &sync.WaitGroup{}
for p := range providers {
   wg.Add(1)
   go func(p peer.ID) {
      defer wg.Done()
      err := pqm.network.ConnectTo(findProviderCtx, p)
      if err != nil {
         log.Debugf("failed to connect to provider %s: %s", p, err)
         return
      }
      select {
      case pqm.providerQueryMessages <- &receivedProviderMessage{
         k: k,
         p: p,
      }:
      case <-pqm.ctx.Done():
         return
      }
   }(p)
}
wg.Wait()
cancel()
```

```
func (im *impl) pinHandle(ctx context.Context, pinCh chan pinOp, wg *sync.WaitGroup) {
   defer wg.Done()
   for {
      select {
      case op, ismore := <-pinCh:
         if ismore {
            _, err := im.store.Take(op.hash, op.peers)
            if err != nil {
               logger.Warnf("error pin %v on %v: %v", op.hash, op.peers, err)
               return
            }
         } else {
            return
         }
      case <-ctx.Done():
         return
      }
   }
}
```





通过我们一个type struct结构体。

start表示运行开启一个协助程序运行run函数。

而context是new这个struct结构体的时候创建的，这样一旦上层close了，这个context代表的所有函数都会close。

run函数不断的循环对各种信息做一个handle处理。

然后开启六个协助程序作为消费者处理真正的任务。





```
func (pqm *ProviderQueryManager) run() {
   defer pqm.cleanupInProcessRequests()

   go pqm.providerRequestBufferWorker()
   for i := 0; i < maxInProcessRequests; i++ {
      go pqm.findProviderWorker()
   }

   for {
      select {
      case nextMessage := <-pqm.providerQueryMessages:
         log.Debug(nextMessage.debugMessage())
         nextMessage.handle(pqm)
      case <-pqm.ctx.Done():
         return
      }
   }
}
```

```
func (pqm *ProviderQueryManager) providerRequestBufferWorker() {
   // the provider request buffer worker just maintains an unbounded
   // buffer for incoming provider queries and dispatches to the find
   // provider workers as they become available
   // based on: https://medium.com/capital-one-tech/building-an-unbounded-channel-in-go-789e175cd2cd
   var providerQueryRequestBuffer []*findProviderRequest
   nextProviderQuery := func() *findProviderRequest {
      if len(providerQueryRequestBuffer) == 0 {
         return nil
      }
      return providerQueryRequestBuffer[0]
   }
   outgoingRequests := func() chan<- *findProviderRequest {
      if len(providerQueryRequestBuffer) == 0 {
         return nil // 注意两边都为空的时候这里也为空
      }
      return pqm.providerRequestsProcessing
   }

   for {
      select {
      case incomingRequest, ok := <-pqm.incomingFindProviderRequests:
         if !ok {
            return
         }
         providerQueryRequestBuffer = append(providerQueryRequestBuffer, incomingRequest)
      case outgoingRequests() <- nextProviderQuery():
         providerQueryRequestBuffer = providerQueryRequestBuffer[1:]
      case <-pqm.ctx.Done():
         return
      }
   }
}
```

如果处理不过来，一方面我们可以用搞一个有缓冲的chan。防止发送方阻塞。

不然可以搞一个无缓冲的chan，但是搞一个无限长度的队列。

我们读取一个无缓冲的chan，把他的请求不断append到一个切片上。

然后消费者也是一个无缓冲的chan，我们select阻塞在其上，一旦可以发送，就从这个slice的头部取出一个值放进去，然后切片移动。