## 为何更改为 4096 字节扇区？

如果您熟悉磁盘结构，就知道磁盘是被分解成*扇区* 的，大小通常是 512 字节；所有读写操作均在成倍大小的扇区中进行。仔细查看，就会发现硬盘事实上在扇区之间包括大量额外数据，这些额外字节由磁盘固件使用，以检测和纠正每个扇区内的错误。随着硬盘变得越来越大，越来越多的数据需要存储在磁盘的每一单位面积上，导致更多低级别错误，从而增加了固件纠错功能的负担。

解决该问题的一个方法是将扇区大小从 512 字节增加为更大的值，以使用功能更强大的纠错算法。这些算法可使每个字节使用较少的数据，从而比使用 512 字节扇区能纠正更多严重问题。因此，更改为较大尺寸的扇区有两个实际好处：提高可靠性且增加磁盘容量 — 至少从理论上讲是这样



### 一、为什么HDFS中块（block）不能设置太大，也不能设置太小？

\1. 如果块设置过大，

  一方面，从磁盘传输数据的时间会明显大于寻址时间，导致程序在处理这块数据时，变得非常慢；

  另一方面，mapreduce中的map任务通常一次只处理一个块中的数据，如果块过大运行速度也会很慢。

\2. 如果块设置过小，

  一方面存放大量小文件会占用NameNode中大量内存来存储元数据，而NameNode的内存是有限的，不可取；

  另一方面文件块过小，寻址时间增大，导致程序一直在找block的开始位置。

因而，块适当设置大一些，减少寻址时间，那么传输一个由多个块组成的文件的时间**主要取决于磁盘的传输速率**。



https://www.maiyewang.com/archives/21911



#### 为什么要分块

1. BitTorrent可以工作。
   - 种子文件本身的大小与片段数成正比。件越多，越大。任何分发或托管种子文件的人都希望保持较小。
   - 数据被切成碎片，因此您一次可以从多个对等点获取少量可验证的数据。每次完全下载一个片段时，都会根据torrent文件告诉您的客户端（使用SHA1算法）进行检查。
   - 该协议依赖于在蜂群中散布碎片。“针锋相对”机制很好用，但前提是您已经有一些数据。因此，通常最难获得前几件。碎片越小，越容易获得。
2. BitTorrent一直在处理碎片。
   - 首先，选择下一个要下载的片段的规则最稀少；如果所有片段均可用，则该规则是随机的。因此，BT客户端必须收集与其连接的每个对等方拥有的每个作品，计算其可用性并选择要下载的作品。而且，每次必须选择一个新作品。件越多，RAM和CPU越多。
   - 每次收到一块时，都会向您连接的所有对等方发送一条“ HAVE”消息，以使他们知道您有该块。片段越多，协议数据中“浪费”的带宽就越多



分块器是完全可配置的。可以是任何东西。256 KB只是基于旧BitTorrent客户端行为设置的默认值。（现代BitTorrent客户端根据制作的种子的总大小选择其分块器大小。）

我总是使用可变大小的滚动Rabin块，因为它在产生可重复数据删除的块方面要好得多。这是一个示例命令，该命令创建的块平均为512 kiB，范围从256 kiB到1 MiB。

- 默认在1  / 3 的blocksize到 3 / 2之间浮动（256kb）
- 使用16字节的windows

```go
// NewRabin creates a new Rabin splitter with the given
// average block size.
func NewRabin(r io.Reader, avgBlkSize uint64) *Rabin {
   min := avgBlkSize / 3
   max := avgBlkSize + (avgBlkSize / 2)

   return NewRabinMinMax(r, min, avgBlkSize, max)
}
```

```
ipfs add -s rabin-262144-524288-1048576 file
```

Rabin分块器对于带有嵌入式元数据（图像，音乐，视频等）的文件格式特别有用。比如说900个人添加了同一首歌曲的相同编码，但其元数据却略有下降。尽管单个文件的元数据不同，但他们仍可以在网络上复制和共享这些文件的大块。

更新：使用Rabin，您甚至可以重复复制嵌入同一张专辑中不同歌曲中的大专辑图像的某些片段。



https://www.cnblogs.com/hadis-yuki/p/5224225.html

- [博客园](https://www.cnblogs.com/)
- [首页](https://www.cnblogs.com/hadis-yuki/)
- [新随笔](https://i.cnblogs.com/EditPosts.aspx?opt=1)
- [联系](https://msg.cnblogs.com/send/fukan)
- [管理](https://i.cnblogs.com/)
- [订阅](javascript:void(0))[![订阅](https://www.cnblogs.com/skins/loveisintheair/images/xml.gif)](https://www.cnblogs.com/hadis-yuki/rss/)

随笔- 104 文章- 1 评论- 4 

# [【转】基于内容可变长度分块(CDC)](https://www.cnblogs.com/hadis-yuki/p/5224225.html)

 基于内容可变长度分块

1，简介
重复数据块检测技术分为，固定分块检测技术(Fixed-Sized Partition, FSP)，可变分块检测技术(Variable-Sized Partition, VSP)，滑动块技术(Sliding Block)。
固定分块将数据流按固定的长度分块，实现很简单，但某一处数据的变化将导致之后的所有分块都发生变化，从而无法进行匹配。因此，固定分块技术在实际中应用较少。可变分块技术则可弥补固定分块技术的这一局限性，能更加灵活的找出重复数据。基于内容可变长度分块(Content-Defined Chunking, CDC)是可变分块(Variable-Sized Partition, VSP)的一种。

2，理论基础
CDC的理论基础是rabin fingerprint，请参照Michael O. Rabin的Fingerprinting by Random Polynomials. 

3，具体实现
文件被分为长度可变的数据块,数据块的长度在一个规定的最小值和最大值之间。可变长度的数据块用一个滑动窗口来划分,当滑动窗口的 hash 值与一个基准值相匹配时就创建一个分块,这样数据块的尺寸就可达到一个期望的分布。Rabin’s fingerprint 预先定义两个整数 D 和 r(r<D) 一个大小为 w 的固定窗口在文件上滑动,
。假如在位置 k,固定窗口内数据的 hash 值为 f。如果f mod D = r,则该位置为数据块的一个边界。重复这个过程,直至整个文件都被分块。

[![img](http://blog.chinaunix.net/attachment/201202/28/25871104_1330396365txtX.png)](http://blog.chinaunix.net/attachment/201202/28/25871104_1330396365txtX.png)
![img](file:///home/hubert/Ubuntu%20One/Notes/deduplication/variable_chunks/pasted_image.png)

实现起来也不是很复杂，但需要对每一次滑动都计算依次窗口内的hash值，计算量增加。另外，如果选择的D和r不合适，会导致窗口过小(很容易匹配上)或过大(不难匹配上)

4，与固定分块技术的对比
现在有一串数据D0：(ABCDEFGHIJKLMNOP)，以固定分块为(ABCD | EFGH | IJKL | MNOP )，假如中间某部分数据发生了变化，数据变为D1：(ABCDEF22GHIJKLMNOP)，那么固定分块为(ABCD | EF22 | GHIJ | KLMN | OP)，除了第一块，其他所有的块都无法完成匹配。
如果采用CDC，假设初始分块也是(ABCD | EFGH | IJKL | MNOP)，那么意味着在D, H, L这三个窗口内，是符合fmodD=r的条件的，当数据发生改变时，由于DHL这三个窗口并未发生改变，他们依然被认定为边界，那么分块有可能变成(ABCD | EF22GH | IJKL | MNOP)，这样，除了发生改变的第二个块不能完成匹配外，其他三个数据块的匹配不会收到影响。

CDC其实早已应用广泛，其最早是用在低带宽环境的数据传输与同步，如rsysnc即使用CDC技术，来检测本次备份与上次备份之间的差异，从而达到只传递差异部分的目的。

https://www.maiyewang.com/archives/21911



这就是为什么我要说“ 2”。确实，归结为：

- 我们不应生成大于1MiB的块。
- 我们应该*拍摄*小于1MiB的方块。
- 所有实现都必须支持最大2MiB的块。
- Bitswap将*拒绝* 超过4MiB的**消息**。这包括块和消息框架。

https://github.com/ipfs/go-ipfs-chunker/pull/21





## 哈希很重要

密码散列具有两个非常重要的特征：

- **确定性** -相同的输入消息始终返回完全相同的输出哈希
- **不相关** -消息中的微小变化应生成完全不同的哈希
- **唯一** -从两条不同的消息中生成相同的哈希值是不可行的
- **单向** -从其哈希值猜测或计算输入消息是不可行的

事实证明，这些功能还意味着我们可以使用加密哈希来识别任何数据：哈希是我们计算得出的数据所独有的，并且哈希不能太长（哈希是固定长度，因此SHA-256哈希是固定长度一个1 GB的视频文件仍然只有32个字节），因此通过网络发送该文件不会占用大量资源。

这对于像IPFS这样的分布式系统至关重要，在该系统中，我们希望能够从许多地方存储和检索数据。运行IPFS的计算机可以询问与之连接的所有对等方是否具有带特定哈希值的文件，如果其中一个具有特定的哈希，则它们将整个文件发回。如果没有像加密哈希这样的短而唯一的标识符，这将是不可能的。这种技术称为[内容寻址](https://docs.ipfs.io/concepts/content-addressing/) -因为内容本身是用来形成地址的，而不是有关存储该计算机和磁盘位置的信息。



如果黑客**不能掌握算法的所有细节**，是不是就**不能算出一组频繁碰撞的键**，也就**没法发动哈希洪水攻击**？

换句话说，我们能不能在算法中加入一个黑客不知道的秘密参数？每建一张哈希表，我们就随机生成一个新的秘密参数。这样一来，即使是同样的内容，放在不同的表里也会产生完全不同的内存分配。这整个过程黑客完全无法预测，即使发生碰撞，也是小概率的巧合，而不是黑客在主动控制，攻击也就不可能成立了

这个黑客不知道的秘密参数，我们现在称之为**哈希种子（Hash Seed）**。而这类使用哈希种子的哈希算法，我们称之为**带密钥哈希算法（Keyed Hash Function）**。

黑客一方的攻击目标，是想办法刺探出种子的值，或者在不知道种子的情况下构造出一组会碰撞的键来。而安全研究人员的目标，就是设计出更安全的带密钥哈希算法，保护好种子的安全，避免种子被黑客绕过。

这些年来，攻守双方在这个领域展开了激烈的攻防，来自Google、UIC等机构的众多研究人员设计了许多新的哈希函数：SipHash、MurmurHash、CityHash等等。这些算法不停地被推翻，不停地更新版本，到现在已经形成了一套稳定的算法标准，被众多编程语言和开源项目所采纳。



作者：Gh0u1L5
链接：https://www.zhihu.com/question/286529973/answer/676290355
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

https://www.zhihu.com/question/286529973



- 快速短输入

![截屏2020-08-02 上午12.46.23](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-08-02 上午12.46.23.png)



#### 优化



- rpc
- 以小文件的形式存储数据
- 不以三副本的策略，而是raid阵列。
- 一致性cache缓存层