#### 拜占庭将军问题

有三个或者更多的将军决定是进攻还是撤退。

通常有一个将军作为司令发布命令。

而底下的作为将军的中尉决定进攻还是撤退。

但是将军会叛变，如果一个司令叛变，会让一个中尉进攻另一个撤退。

如果一个中尉叛变。他会告诉一个中尉说司令让他进攻。

而告诉另一个中尉司令让他撤退。



如果将军之间发送的消息没有经过签名。

叛徒将军数量小于总将军的三分之一，那么无解。



终止性：

最终每个进程都要做出决定。



和共识算法的区别：

- 一个独立进程提议一个值，其他进程决定是否采取
- 共识是每个进程都提供一个值

#### n <= 3f进程的不可能性

如果三个进程中有一个是叛徒。



在这种情况下，有可能司令是叛徒也有可能中尉是叛徒。

但是正确的中尉只知道自己收到了两个不一样的值。

区分不了哪个是将军。





完整性：如果司令正确，那么所有正确的进程都采取司令的值。

所以中尉在司令正确的情况下，必须采取司令的值。

如果无法区分，那么它还是得选择司令发生的值。



但是如果所有的中尉都决定采取司令发送的值。

这就破坏了协定性：所有正确进程决定的值相同。



因为司令会给不同的中尉发送不同的值。

#### n <= 3f

不可能有解决方案。

我们可以通过三个进程模拟n个进程的情况。

每个n1 + n2 + n3 = N，但是每个进程n1, n2, n3 <= 3/ n。

三个进程中有一个错误，就说明最多3 / n个将军出错。



我们假设进程运行的算法是正确的。

因此模拟能够终止：每个正确进程都做出决定。

#### n >= 3f + 1

两轮消息一致：

- 司令给每个中尉发送一个值
- 中尉将收到的消息发送与自己桶级别的人。



只要取一个简单的majority函数就行了。

因为一个中尉收到的正确消息要大于错误消息的数量。



如果没有收到信息，将相当于收到了一个特殊值，然后继续处理。

需要进行f + 1轮信息传递。

#### 如果消息能够进行签名

那么有解。

#### raft和区块链

一类是故障容错算法 (Crash Fault Tolerance, CFT)， 即非拜占庭容错算法，解决的是分布式系统中存在故障，但不存在恶意攻击的场景下的共识问题。也就是说，在该场景下可能存在消息丢失，消息重复，但不存在消息被篡改或伪造的场景。一般用于局域网场景下的分布式系统，如分布式数据库。属于此类的常见算法有 Paxos 算法、Raft 算法、ZAB 协议等。一类是拜占庭容错算法，可以解决分布式系统中既存在故障，又存在恶意攻击场景下的共识问题。一般用于互联网场景下的分布式系统，如在数字货币的区块链技术中。属于此类的常见算法有 PBFT 算法、PoW 算法。





[https://bbs.vechainworld.io/topic/176/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%97%B6%E4%BB%A3%E7%9A%84%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E4%BB%AC-%E4%B8%8A](https://bbs.vechainworld.io/topic/176/区块链时代的拜占庭将军们-上)



#### raft为什么能实现flp

从处理的问题上来看，Paxos仅能处理故障容错，并不难处理拜占庭错误，所以属于非拜占庭容错算法。从FLP的视角，Paxos做到了故障容错和安全性，但放弃了liveness（safe but not live）,也就是说该算法可能永远无法结束，或者说永远无法达成共识，虽然这种可能性极小。从CAP的视角，Paxos只保证了CP，即做到了分区容错性和一致性，但弱化了可用性。有时为了增强paxos系统的可用性，可以考虑增加learner角色的数目。



而raft对安全性的保证是通过只有leader可以决定是否commit来实现的。

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

#### 异步网络

在同步网络中，存在某个延迟t，任何两点之间的通信消息延迟都小于t。

在异步网络中，不存在这么个t。

也就是说我们无法通过超时来判断进程是否已经崩溃还是只是很慢而已。



[https://bbs.vechainworld.io/topic/176/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%97%B6%E4%BB%A3%E7%9A%84%E6%8B%9C%E5%8D%A0%E5%BA%AD%E5%B0%86%E5%86%9B%E4%BB%AC-%E4%B8%8A](https://bbs.vechainworld.io/topic/176/区块链时代的拜占庭将军们-上)

#### flp

异步系统中即使一个进程出现故障，也没有算法能保证达到共识。

假如我们设计一个算法P，每个节点根据多数派表决的方式判断本地是提交还是回滚：

假如C收到了A、B的提交申请，收到了D的回滚申请，而C本身也倾向于回滚，此时，提交、回滚各有两票，E的投票决定着C的最终决议。而此时，E失败了，或者E发送给C的消息被无限延迟（无法探测失败），此时C选择一直等待，或者按照某种既定的规则选择提交或失败，后续可能E正常而C失败，总之，导致C没有做出最终决策，或者C做了最终决策失败后无人可知。称所有进程组成的状态为Configuration，如果一系列操作之后，没有进程做出决策称为“不确定的”Configuration；不确定Configuration的意思是，后续可能做出提交，也可能做出回滚的决议。



https://www.cnblogs.com/firstdream/p/6585923.html

### **活性（liveness）与安全性（satefy）**

安全是说系统内各个节点达成的值是一致的、有效的。safety其实是保证系统一致性运行的最低要求，其核心是cannot do something bad，即不能干坏事、不能做错事。

活性是说系统内各个节点最终（在有限时间内）必须能够达成一致，即系统必须能够向前推进，不能永远处于达不成一致的状态。liveness其实是更高要求，意味着不能只是不干坏事，也不能一直不干事，you must do something good，即必须使得整个系统能良好运转下去。

容错是说该协议在有节点故障的情况下也必须能有效

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



FLP不可能定理其实意味着在异步网络中，不可能存在同时满足这三者的分布式一致性协议。因为分布式环境中，节点故障几乎是必然的，因此容错是必须要考虑的因素，所以FLP不可能定理就意味着一致性协议在能做到容错的情况下，没办法同时做到安全性与系统活性。通常在实践中，我们可以做出部分牺牲，比如牺牲一部分安全性，意味着系统总能很快达成结论，但结论的可靠性不足；或者牺牲一部分系统活性，意味着系统达成的结论非常可靠，但可能长时间、甚至永远都在争论中，无法达成结论。所幸的是，很多时候现实世界的鲁棒性很强，使一致性协议失效的倒霉事件发生的概率也很可能极低

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



要澄清一下，这个发现没有证明共识不能达成。而且——因为消息异步传递，所以“不可能”在固定时间达成共识——这里说的“不可能”，指的是共识“并非总能”达成。这是个微妙但至关重要的细节。

这个规避 FLP 不可能问题的方法就是引入超时（timeout）的概念。如果在确认下个值的过程没有进展，我们会等到超时，然后重新进行共识的步骤。如我们所见，Paxos 和 Raft 使用的就是这类共识算法。



（如果不断竞争，将有可能无线延期，可能无法终止）。



活性与安全性，这个要怎么理解呢？



容错是说该协议在有节点故障的情况下也必须能有效。

因为分布式环境中，节点故障几乎是必然的，因此容错是必须要考虑的因素，所以FLP不可能定理就意味着一致性协议在能做到容错的情况下，没办法同时做到安全性与系统活性。（强调分布式环境中节点故障的必然性以及p分区的必然性。）

刚刚说到，当A向B发送请求，B没有及时回应。但这个时候，A是无法准确知道B真正的状态的（忙于其他任务还是真的挂掉了），也就是说**我们是无法做到完全正确的错误检测**。

这种时候按照上面的说法，有两种选择，

1. 任务B依旧或者，无限重试，不断等待。
2. 直接认为B挂掉了，进行错误处理。

选择1，破坏了系统的活性，因为在重试的时间内，系统是无法对外提供服务的，也就是短暂得失活了。

选2呢又破坏了安全性，因为如果B其实没有挂掉，而这时候重新启动一个节点负责原本B的工作，那么此时系统中就会有旧的B节点，和新的B节点。**此时旧的节点就称之为僵尸节点（Zombie）**。而如果在主从分布的系统，也就是一个leader多个follower的系统中，如果B刚好是leader，那么这种情况也被称之为脑裂。

可以发现，liveness和响应速度有关，而satefy又和系统的可用性相关，并且这两者是不可兼得的。

https://zhuanlan.zhihu.com/p/109800670



FLP面对的是分布式一致性问题，而CAP面对的是分布式网络中的数据同步与复制。

FLP是说在异步网络模型中，三者不可能同时实现；而CAP是说在所有场景下，三者都不可能同时实现。

FLP中的liveness强调的是一致性算法的内在属性；而CAP中的availability强调的是一致性算法对外呈现的外在属性


作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

#### 牺牲正确性

本质上我们不能保证算法会终止

#### 比特币

比特币系统由用户（用户通过密钥控制钱包）、交易（每一笔交易都会被广播到整个比特币网络）和矿工（通过竞争计算生成在每个节点达成共识的区块链，区块链是一个分布式的公共权威账簿， 包含了比特币网络发生的所有的交易）组成。



比特币交易建立和签名时不用连接比特币网络。只有在执行交易时才需要将交易发送到网络。

#### 区块链

区块链之间通过引用上一个区块的hash。

以及merkle树维护交易的完整性

![截屏2020-07-14 下午2.25.42](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-14 下午2.26.34.png)

区块主标识符是它的加密哈希值，一个通过SHA256算法对区块头进行二次哈希计算而得到的数字指纹。

![截屏2020-07-14 下午2.28.22](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-14 下午2.28.22.png)

矿工们验证每笔新的交易并把它们记录在总帐簿上。每10分钟就会有一个新的区块被“挖掘”出来，每个区块里包含着从 上一个区块产生到目前这段时间内发生的所有交易，这些交易被依次添加到区块链中。我们把包含在区块内且被添加到 区块链上的交易称为“确认”（confirmed）交易，交易经过“确认”之后，新的拥有者才能够花费他在交易中得到的比特币。

矿工们在挖矿过程中会得到两种类型的奖励：创建新区块的新币奖励，以及区块中所含交易的交易费。为了得到这些奖 励，矿工们争相完成一种基于加密哈希算法的数学难题，这些难题的答案包括在新区块中，作为矿工的计算工作量的证 明，被称为”“工作量证明”。该算法的竞争机制以及获胜者有权在区块链上进行交易记录的机制，这二者是比特币安全的基石。

#### 挖矿

▷ 每个全节点依据综合标准对每个交易进行独立验证

▷ 通过完成工作量证明算法的验算，挖矿节点将交易记录独立打包进新区块

▷ 每个节点独立的对新区块进行校验并组装进区块链

▷ 每个节点对区块链进行独立选择，在工作量证明机制下选择累计工作量最大的区块链。



通过反复修改nonce 来生成不同哈希值的脚本的输出



为了使这个哈希算法变得富有挑战，我们来设定一个具有任意性的目标：找到一个语句，使之哈希值的十六进制表示以 0开头。幸运的是，这很容易！在例10-10中语句 "I am Satoshi Nakamoto13" 的哈希值是 0ebc56d59a34f5082aaef3d66b37a661696c2b618e62432727216ba9531041a5 ，刚好满足条件。我们得到它用了13次。用概率的角度 来看，如果哈希函数的输出是平均分布的，我们可以期望每16次得到一个以0开头的哈希值（十六进制个位数字为0到 F）。从数字的角度来看，我们要找的是小于 0x1000000000000000000000000000000000000000000000000000000000000000 的哈希值。

我们称这个为Target目标阈值，我们的目的是找到一个小于这个目标的哈希值。如果我们减小这个目标值，那找到一个小于它的哈希值会越来越难。



比特币共识机制的第三步是通过网络中的每个节点独立校验每个新区块。当新区块在网络中传播时，每一个节点在将它 转发到其节点之前，会进行一系列的测试去验证它。这确保了只有有效的区块会在网络中传播。独立校验还确保了诚实 的矿工生成的区块可以被纳入到区块链中，从而获得奖励。行为不诚实的矿工所产生的区块将被拒绝，这不但使他们失 去了奖励，而且也浪费了本来可以去寻找工作量证明解的机会，因而导致其电费亏损。

![截屏2020-07-14 下午2.35.34](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-14 下午2.35.34.png)

要生成这样的一个私钥，我们随机选择一个256位的数字。

通过椭圆曲线乘法可以从私钥计算得到公钥，这是不可逆转的过程：K = k * G 。



以公钥 K 为输入，计算其SHA256哈希值，并以此结果计算RIPEMD160 哈希值，得到一个长度为160位（20字节）的数字：

A = RIPEMD160(SHA256(K))

公式中，K是公钥，A是生成的比特币地址。



具体地，Base58不含Base64中的0（数字0）、O（大写字母o）、l（小写字母 L）、I（大写字母i），以及“+”和“/”两个字符。简而言之，Base58就是由不包括（0，O，l，I）的大小写字母和数字组成。

例4-1 比特币的Base58字母表

123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz



#### pow

用共识算法的思路来说Proofof Work的思路，在POW共识中有一个假设就是网络同步是有延迟的，但是延迟是有界的，并不会发生无限的延迟。而第一个解决数学难题的人，比如算出来一个特定的hash，这个人就是Leader，而Leader生成的区块才是有效的，POW的设计是非常简洁和有效的。

#### 安全

这些激励策略也隐含地鼓励了节点保持诚实，若某个贪婪的攻击者真的拥有了过半的CPU算力，他不得不做出选择：到底是篡改交易记录，把他已经花出去的比特币再转回来呢？还是老老实实地挖矿赚钱新币和手续费呢？很可能，老老实实地挖矿是更有利的，毕竟能赚到的币比其他所有节点加起来都要多；而破坏比特币体系也将会破坏自身财富的有效性，毕竟若比特币不再可靠，其价值也会迅速崩溃。这里多提一点，攻击者并不像一般人想象的那样可以为所欲为、任意篡改或伪造交易记录，他能做的只可能是将其最近花出去的比特币偷回来。

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



有效的激励策略：通过激励策略有效地激励了更多节点参与到比特币的点对点网络中，节点越多比特币网络越安全。

PoW：挖矿出块需要消耗CPU算力，人为地制造障碍、增加成本，提高了攻击者的作恶成本。

博弈论思想：激励策略也考虑了博弈平衡，理性节点保持诚实的收益更大。

通讯效率：比特币节点间的通讯效率并不低效，大家可能注意到其中也涉及到了交易和区块的广播，不过这种广播并非是两两广播，而是由某个节点（发生交易或算出PoW的节点）将信息广播到其他所有节点。另外，交易广播并不要求触达所有节点，只要有许多节点接受，不久之后就会被打包。2014年也有Miller等人（Anonymous Byzantine Consensus from Moderately-Hard Puzzles: A Model for Bitcoin）严格证明，消息复杂度并不随网络大小而增大，而是一个常数。另外，区块广播也容许消息丢失，若某个节点未收到某个区块，则当它接收到下个区块时，会意识到自己遗漏了上个区块，而主动向其他节点请求该区块。

概率性的一致性：相比其他一致性算法，比特币的共识机制最特别的是不再追求确定性的一致性，而是追求概率性的一致性。当某个区块刚被挖出的时候，其包含的交易信息并非被所有节点最终确认、其包含的数据并非是最终一致性的结果，还是有可能被攻击者篡改的；但是随着后续节点数目的增多，这种被篡改的可能性指数下降，最终一致性的概率显著增大；一旦后续节点超过6个（也就是经过约60分钟），这种一致性就可以被认为是确定的、最终的。

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



比特币最大程度地考虑了故障容错和网络分区容错，这也是对网络openness的必要要求，因为开放网络环境极其复杂，谁都可以随时进出，节点遍布全球各地，机器故障、网络分化、系统攻击随时可能发生，容错是必须需要考虑应对的。而利用PoW机制，比特币不仅做到了故障容错，而且结合密码学非对称加密技术，也可以做到拜占庭容错，抵御恶意篡改与攻击。

比特币尽可能地保证了liveness和availability，比特币的出块时间总是在10分钟左右，这也就意味着系统总可以在10分钟内达成一致；比特币网络十年来不曾瘫痪，从这个角度来讲确实将可用性做到了极致。然而，我们必须指出，比特币的可用性与我们通常理解的互联网领域的可用性是有很大差异的。互联网领域的系统可用性，不仅要求系统稳定运行不宕机，还对服务体验如响应时间有明确要求。如果你用支付宝转账，不是随时可转、3秒到账，而是告诉你系统繁忙，需要等待10分钟、甚至30分钟，这显然会被认为服务不可用。然而，这一现象在比特币中一直在发生，比特币每10分钟一个区块，而区块大小只有1M，装不下太多交易，若同一时间交易过多，只能一直等待，直到能被下一个区块打包进去，所以经常可能需要等待20分钟、30分钟、甚至更久。从这一角度对比来看，其实比特币网络放宽了对响应时间的要求，做到了比较基本的可用性：读的可用性极高，而写的可用性很低。

比特币对于safety和consistency，不再追求确定性，而是采用了概率性的保障，基本可以认为保证了最终安全性和最终一致性，只不过这里的“最终”依然是有时间条件的、基于概率的。比如，如果我刚刚给你转账了一个比特币，没人敢说这个结果是确定的、最终的，但是随着时间的推移，不断有新的区块被挖出，我转账的交易信息也会被更多的节点确认、被更多的后续区块强化，这一结果确定性的概率不断增大，一旦过了足够的时间（如1个小时），我们从概率角度可以认为结果被篡改的可能性极低，系统达成最终一致性的概率极高，从实践上就可以认为系统保证了最终的一致性。

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



其实，大家可能也意识到了，PoW的思想并不高深，事实上也并非是中本聪首创。早在1993年这一思想就被提出用于对抗垃圾邮件(Pricing via Processing or Combatting Junk Mail)，但直到中本聪创造比特币之前，这一思想都尚未得到广泛应用。PoW思想的精髓就在于故意制造障碍、增加参与者的成本，以尽量降低参与者的恶意企图。比如要求请求者做些额外的工作以检测DDoS攻击、垃圾邮件等，也比如最常见的登录网站需要输入验证码，也是为了增加登录成本，防止网站被攻击。这类任务最核心的特征是非对称：对于服务请求者来说，完成任务必须有一定难度；而对服务提供者来说，验证任务必须很简单快速。对于比特币PoW而言，显然符合非对称性：不断试错，寻找使哈希符合条件的nonce（随机数）需要消耗大量算力，而验证寻找到的nonce是否符合条件只需要做一次简单的哈希运算验证即可。

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



效率低下：大家习惯了互联网的便捷，习惯了秒级到账和百万级别的TPS，对于比特币交易动辄需要等待几十分钟，每秒钟仅能支持7笔交易，显然不太满意。虽然这种对比也并不公正，毕竟银行系统后台只有几个机房、最多百台机器，并且交易只进入到了其中某台机器，事后的清算环节才保证了最终一致性；而比特币无任何单点，协调的是上万台机器，并且交易即清算。不过这种效率的低下也确实是事实，也不断有人尝试改进，如把比特币每个区块的size limit调大，让其每个区块能打包更多的交易，bitcoin cash就是这么干的；再如把比特币的出块时间改小，让其更快出块，litecoin就是这么干的。但即便如此，PoW为了保证网络安全性而要求的巨大的工作量证明成本，也注定了网络的效率很难有质的提升。

中心化风险：随着ASIC和FPGA等特制挖矿芯片的出现，普通个人PC想挖出比特币几乎是天方夜谭。挖矿越来越集中到有实力研发芯片的巨头企业上，而矿池（为了平滑收益大量节点组成联盟共同挖矿、平分收益）的出现也加剧了这一趋势。另外，对比特币block size limit的调大，也会导致运行比特币全节点需要庞大的存储空间，以至于无法在普通PC上运行，而只能运行在特制的大型计算机上。这些中心化的倾向无疑都会损害比特币网络的安全性，毕竟由全世界各个角落的普通PC构成的比特币网络的安全性远远高于由几个巨头公司直接或间接控制的比特币网络。虽然这一问题的争议更大，仁者见仁，但仍然有很多人在尝试寻求新的解决思路。

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

#### 双花

是通过时间戳（Timestamp）和工作量证明（Proof of Work）机制解决双重支付（Double Spending）和拜占庭将军问题（Byzantine Generals’ Problem），



一方面，每一笔付款都会被广播给系统中所有节点，任何人都可以使用收款者的公钥来验证这个交易的合法性，如果付款者试图双重支付，就必须先删除这个交易记录，否则新交易无法通过验证。中本聪在论文中写道：



“时间戳服务器为一个区块的数据的哈希计算结果加上时间戳，并大范围发布这一哈希计算结果，好比在报纸或新闻网上发表。显然，时间戳证实这些数据一定在这一特定时间存在，只有这样才能得到哈希计算结果（*A timestamp server works by taking a hash of a block of items to be timestamped and widely publishing the hash, such as in a newspaper or Usenet post. The timestamp proves that the data must have existed at the time, obviously, in order to get into the hash*）”。



作者：知乎用户
链接：https://www.zhihu.com/question/39948446/answer/108408014
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



作者：知乎用户
链接：https://www.zhihu.com/question/39948446/answer/108408014
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



另一方面，工作量证明机制使得生成下一个区块的节点和矿工几乎无法被预测到（重点），所以删除交易记录几乎不可能。系统中的节点将过去约10分钟内的比特币交易进行打包，而只有获得有效哈希值的矿工才能生成新区块，并得到挖矿奖励；矿工除了打包比特币交易，还要结合随机数来完成有效哈希值的创建工作，获得以要求的数量的0作为开始的哈希值。中本聪在论文中写道：



“工作量证明本质上是一CPU一票（*Proof-of-work is essentially one-CPU-one-vote*）”；“如果两个节点同时广播不同版本的新区块，那么一些节点会先收到其中一个的广播。在这种情况下，节点在先收到的区块基础上工作，并保留另外一个分支，以防后者变成较长的链。这个僵局要等到发现下一个工作量证明才能被打破，其中一条链将成为较长的链，在另一个分支上工作的节点将切换到较长的链上继续工作（*If two nodes broadcast different versions of the next block simultaneously, some nodes may receive one or the other first. In that case, they work on the first one they received, but save the other branch in case it becomes longer. The tie will be broken when the next proof-of-work is found and one branch becomes longer; the nodes that were working on the other branch will then switch to the longer one*）”；“节点永远认为最长的链是正确的链，并将持续在它上面延长（*Nodes always consider the longest chain to be the correct one and will keep working o![截屏2020-07-14 下午3.03.10](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-14 下午3.03.10.png)n extending it*）”，所以除非永久控制整个系统中超过一半的节点，才能阻止矿工把这个交易添加到新区块中。

#### cap

https://zhuanlan.zhihu.com/p/50990721

- 一致性（**C**onsistency） （等同于所有节点访问同一份最新的数据副本）
- [可用性](https://zh.wikipedia.org/wiki/可用性)（**A**vailability）（每次请求都能获取到非错的响应——但是不保证获取的数据为最新数据）
- [分区容错性](https://zh.wikipedia.org/w/index.php?title=网络分区&action=edit&redlink=1)（**P**artition tolerance）由于分布式系统通过网络进行通信，网络是不可靠的。当任意数量的消息丢失或延迟到达时，系统仍会继续提供服务，不会挂掉。换句话说，分区容忍性是站在分布式系统的角度，对访问本系统的客户端的再一种承诺：我会一直运行，不管我的内部出现何种数据同步问题，强调的是不挂掉。

理解CAP理论的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了C性质。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了A性质。除非两个节点可以互相通信，才能既保证C又保证A，这又会导致丧失P性质。



这里的c说的是任意时刻都是一致的。

![截屏2020-07-14 下午3.17.29](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-14 下午3.17.29.png)

之前提到,CAP理论说一个分布式系统不可能同时满足C、A、P这三个特性。那么我们就来分析C、A、P的权衡吧。

> **note：**其实这里有个关于CAP理论理解的误区。不要以为在所有时候都只能选择两个特性。在不存在网络失败的情况下（分布式系统正常运行时），C和A能够同时保证。只有当网络发生分区或失败时，才会在C和A之间做出选择。

对于一个分布式系统而言，P是前提，必须保证，因为只要有网络交互就一定会有延迟和数据丢失，这种状况我们必须接受，必须保证系统不能挂掉。所以只剩下C、A可以选择。要么保证数据一致性（保证数据绝对正确），要么保证可用性（保证系统不出错）。

当选择了C（一致性）时，如果由于网络分区而无法保证特定信息是最新的，则系统将返回错误或超时。

当选择了A（可用性）时，系统将始终处理客户端的查询并尝试返回最新的可用的信息版本，即使由于网络分区而无法保证其是最新的





假设N1和N2之间通信的时候网络突然出现故障，有用户向N1发送数据更新请求，那N1中的数据DB0将被更新为DB1，由于网络是断开的，N2中的数据库仍旧是DB0；

如果这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据DB1，怎么办呢？有二种选择，第一，牺牲数据一致性，响应旧的数据DB0给用户；第二，牺牲可用性，阻塞等待，直到网络连接恢复，数据更新操作完成之后，再给用户响应最新的数据DB1。

#### acid

acid就是ca，没有p分区



## 3.1 基本可用（Basically Available）

基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。

电商大促时，为了应对访问量激增，部分用户可能会被引导到降级页面，服务层也可能只提供降级服务。这就是损失部分可用性的体现。



## 3.2 软状态（ Soft State）

软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。



## 3.3 最终一致性（ Eventual Consistency）

最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。



基本可用是指分布式系统在出现不可预知故障的时候，允许**损失部分可用性**——但请注意，这绝不等价于系统不可用。一下就是两个"基本可用"的例子。

- **响应时间上的损失：**正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障（比如系统部分机房发生断电或断网故障），查询结果的响应时间增加到了1~2秒。
- **功能上的损失：**正常情况下，在一个电子商务网站（比如淘宝）上购物，消费者几乎能够顺利地完成每一笔订单。但在一些节日大促购物高峰的时候（比如双十一、双十二），由于消费者的购物行为激增，为了保护系统的稳定性（或者保证一致性），部分消费者可能会被引导到一个降级页面，如下：



作者：Jeffbond
链接：https://www.jianshu.com/p/68c7c16b3fbd
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



BASE 主张放弃掉 ACID，主要是放弃 ACID 中的 Consistency，并且让系统达到基本可用（Basically Available），柔性状态（Soft State），最终一致（Eventual Consistency）。系统构建者可以不仅仅选择 ACID，BASE 也称为一种选择，也就是在 ACID 和 BASE 中选择其一。本质上来讲，就是在 ACID 代表的一致性 (Consistency) 和 BASE 代表的可用性（Availability）二者之间做出选择。虽然在 BASE 提出时，还没有明确说明在一致性和可用性间做出架构选择，但是已经为后面 CAP 的提出做好了伏笔。



对于服务请求者来说，完成任务必须有一定难度；而对服务提供者来说，验证任务必须很简单快速。对于比特币PoW而言，显然符合非对称性：不断试错，寻找使哈希符合条件的nonce（随机数）需要消耗大量算力，而验证寻找到的nonce是否符合条件只需要做一次简单的哈希运算验证即可。

比特币的PoW本质上是one-CPU-one-vote，一个CPU投一票。为什么选择CPU，而不是IP地址呢？这仍然是基于任务难度考虑，若是one-IP-one-vote，则系统可以被拥有大量IP地址的人（如ip供应商）轻易控制。相对而言，至少在当时（尚未出现ASIC和FPGA）CPU仍然是比较昂贵的硬件，想拥有大量的算力（CPU+电力）并不容易。当然，这其实也隐含地为比特币的价值提供了现实锚定：虚拟的货币体系通过算力找到了现实物理世界的价值锚定，虽然在很多人看来这种算力的消耗是毫无意义、浪费能源的。


作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。





#### pos

所有节点不再同时竞争挖矿，而是每次仅有1个节点做验证者：在比特币网络中，所有节点都需要做PoW任务，也就是说都需要做复杂的哈希运算而消耗大量CPU算力，而只有最先找到答案的节点才能获得奖励。这种所有节点间的同时竞争挖矿无疑需要消耗大量资源，那么是否可以每次只有一个节点工作呢？如果可以，那怎么选定这个幸运儿呢？PoS中不再需要挖矿，不再有miner，而是每次只需要选出一个节点作为validator去验证区块的有效性。如果某个节点被选为validator来验证下一个区块，它将验证该区块内的所有交易是否有效。如果所有交易都验证有效，则该节点对该区块进行签名，并添加到区块链上。作为回报，该validator将会收到这些交易相关的交易费用。显然，在PoS中每次共识只有一个节点付出了劳动，且该劳动非常轻松，从而达到了节约资源的目的。

想成为validator必须提供保证金：为了防止validator作恶，想成为validator必须提前往指定账户存入代币作为保证金或抵押担保金，一旦被发现作恶，则保证金即会被罚没，而诚实工作将会得到激励。显然，只要作恶带来的收益不超过保证金额度，节点就会老老实实地保持诚实。

被选为validator并不是完全随机的，而是被选定概率与提供的保证金金额成正比：例如Alice提供100个币的保证金，而Bob提供500个币的保证金，则Bob被随机选为validator从而产出下一个区块的概率是Alice的5倍。这其实就类似于股份制公司，按照出资比例来划分发言权、最终受益权等，大股东出资多、承担责任大、相应的回报也大。

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



然而，对这一问题的看法争议很大，很多人提出了完全不同的看法，认为PoS相比PoW更公平、更有助于对抗中心化趋势。理由主要是：PoW挖矿依赖现实世界的物理硬件和电力资源，而这很容易带来规模经济（Economies of scale）优势。购买10000台矿机的公司相比购买1台矿机的个人更有议价权，甚至可以自主研发成本更低的矿机；而拥有10000台矿机的矿场，对电费的议价权也更高，甚至可以搬迁到电费便宜的国家和地区的电站旁边，甚至可以自建成本更低的电站。由此带来的后果就是越庞大的组织的综合挖矿成本越低，而这正是现实世界真实已经发生的事实。相比之下，PoS不需要依赖现实硬件，不存在规模经济优势，在不考虑价格操纵的情况下，买1个币的价格和买10000个币的价格是线性增加的，从这个角度理解，PoS可能更公平，更有助于去中心化

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



前文所说的根据账户资金按比例按概率选择其实是最简单的一种方式，这种方式确实容易导致有钱人获得一劳永逸的收益，从而损害网络中其他参与者的积极性。



基于PoS改进的比较有名的方案当属Delegated Proof-of-Stake（DPoS），其中采用了代理人委托机制。在DPoS中不再是所有节点都有可能成为creator，而是节点间相互投票，只有得票最高的一些节点才可能参与区块创造过程。具体如下：

- 代理人的职责包含保证自身节点持续运行、收集交易信息并打包到区块中、签名验证并广播区块、解决网络中可能存在的一致性问题。
- 对于大多数DPoS链来说，网络中的所有持币人（token holders）都可以向代理人投票，且投票权与持币数量成正比。用户也可以不直接投票，而把投票权委托给其他人来代表他们投票。
- 投票是动态的、可变的，意味着某个代理人随时可能被选进来或选出去。而一旦某个代理人被发现作恶或欺诈，就将失去收入和名誉，这就起到了激励代理人保持诚实、保证网络安全的目的。代理人可以将收到的区块奖励按比例分给向他投票的用户（这其实相当于贿选，在有些方案中不被允许）。
- 不像传统的PoS，代理人不再需要持有大量的代币，而是必须相互竞争从持币者那里争取投票。
- DPoS限制了交易区块的验证者人数，这相当于牺牲了一定程度的去中心化，但却带来了效率的提升，因为网络达成共识所需的工作量大幅降低。

作者：阿里云云栖号
链接：https://juejin.im/post/5cd91fbff265da03555c9e65
来源：掘金
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。



#### 为什么区块链不使用分布式

。而BFT解决这个问题的思路是需要2/3的数据达到一致性，对于一致性数据进行投票，这个思路是解决先有分布式系统采用最多的。但是这个方案在区块链项目中却无法实现，BFT在一个去中心化的系统中无法解决女巫攻击的问题。

其实本质是拜占庭问题。

#### nothing of stack

矿。每个其他人都将继续在蓝色链上挖矿，因为在最长的链上挖矿收益更可观，而且没有风险。

记住，工作量证明在资源方面是非常昂贵的。对一个矿工来说，花费许多资源在一个将会被网络拒绝的区块上是没有任何意义的。因此，链分裂在一个工作量证明系统中是被避免了的，因为攻击者将不得不付出大量金钱。

但是，当你把这种情形放到到权益证明下的时候，事情看起来就有些不一样了。如果你是一个验证者，你可以简单地把钱投到红蓝两条链上，完全无需担心间接的不良后果。不管发生什么事，你都总是可以赢，不会失去任何东西，不管你的行为有多恶意。

这就是所谓的“无利害关系（Nothing at Stake）”问题，也是以太坊必须解决的问题。他们需要一种协议，可以实行权益证明，同时减少“无利害关系”问题。![截屏2020-07-22 下午9.21.16](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-22 下午9.21.16.png)