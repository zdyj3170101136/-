
#### 虚拟内存

虚拟内存，一般是因为需要使用的内存大于实际物理内存，但只有一部分是实际使用的。

一般空指针为虚拟地址0，不会映射到任何地方。

 cpu通过page table把虚拟的页号映射到实际的页号。

（只有应用层才需要，内核都是直接访问）



页面大小一般为4K。

#### page table

page table包括对虚拟内存的描述，权限和位置长度等。

一般进程申请内存就会分配page table。

但是实际访问的时候才会分配物理内存。

按需分配。



SIGSEGV（访问野指针，导致的内存退出。也就是没和page table关联的信号量）

#### file backed

对应的资源为磁盘上的文件，信息包括文件位置，offset，权限。

第一次访问会page fault中断，将实际内存加载到物理内存中

以这种形式加入到内存的数据都会放入page cache中

#### device backed

映射到物理磁盘的物理地址，比如物理内存被swap out后。

#### anonymous

程序自己的数据段和堆栈空间，由于磁盘上找不到文件，所有称为anonmous。

如果内存吃紧。

file backed可以直接删除。（非脏数据）

ananymap 需要swap out。

#### shared

表示和其他进程共享的数据

#### copy on writr

当写的时候才分配，读不处理。

#### MMU

输入虚拟地址和page table，输出物理地址

#### tlb

tlb保存在cpu的l1cache里头，缓存物理地址到虚拟地址的映射。

https://segmentfault.com/a/1190000008125006#item-6-2

#### huge page

https://cloud.tencent.com/developer/article/1485099

1.增加TLB的命中率

2.Page是被锁定在内存中，降低内存交换；

3.锁定内存，降低内存释放与占用产生的性能降低；

4.提高内存的性能，降低CPU负载。

#### cache

#### buffer cache

缓存块设备id和块的编号到具体数据的映射。

#### page cache

文件id 到对应文件数据的映射。

实际上buffer cache只缓存page cache 不缓存的东西。

比如文件元数据

https://segmentfault.com/a/1190000008125006#item-6-2



所有`Page Cache`里的页面都是`File-backed Pages`，`File-backed Pages`在内存不足的时候可以直接写回对应的硬盘文件里，即`Page-out`。而`Anonymous Pages`在内存不足时就只能写到硬盘上的交换区`Swap`里来释放内存，称之为`Swap-out`。

`Anonymous Pages`与用户进程共存，进程退出则`Anonymous pages`释放，而`Page Cache`即使在进程退出后还可以缓存。



pagecache时系统级别的

http://www.0xffffff.org/2019/07/17/42-linux-memory-monitor/

#### swap

当内存不够用的时候换出。

- 对于服务器，使用swap可能导致苟延残喘一会，几乎中断

- 不实用swap就是删掉号内存的进程然后重启。顶多中断一小会而。

  一般不用swap，

https://segmentfault.com/a/1190000008125116

#### l ru

完全准确的执行lru代价太高。因为每次都得更新数据结构。





当前发生缺页中断时，把最长时间没有使用的页面置换掉。

通常通过一个map和一个链表实现。



实际上不会在缺页的时候才是系统空闲。



因此会定期扫描内存。将内存控制在高低水位。

Linux区分四种不同的页面：不可回收的、可交换的、可同步的、可丢弃的。

页面回收时做一下子判断。

（而我们通过filebacked和annoanymous两个不同的lru链表作出判断/）

- ![截屏2020-07-10 下午5.09.24](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-10 下午5.09.24.png)

#### swap cache

如果当页面换出时，先把内容写进磁盘，同时修改内存标志位。

但是内存不l立刻释放。

这样，如果刚被换出就需要立刻访问，就可以从swap cache中找出，减少抖动。

#### active 和 inactive

linux分为file和anmuous两种页面。

其中又包括active和inactive总共四种lru页面。



如果swappiness的值为0，那么内核在启动内存回收时，将完全忽略anonymous pages，这将带来一个好处，就是内核只需要扫描page cache对应的inactive list（LRU_ACTIVE_FILE）就可以了，根本不用扫描anonymous pages对应的inactive list（LRU_ACTIVE_ANON），这样能极大的节约内存回收时花在扫描LRU链表上的时间。



active主要是判断是否是活跃的，referrence用来判断是否是最近访问过。

如果只有一个标志位的话，那么需要在一定时间内清除，需要定时器保证。

由于定时器很少支持，因此使用标志位



链表间移动FIFO。



inactive越长，那么抖动更少。但是soft page fault更多。

因为内存固定。



当前仅仅确保active 不要 超过 inactive。



对于文件来说第一次访问就会被移入到inactibe list。因为文件通常只访问一次。

http://tinylab.org/lwn-495543/

#### page cache

一般回收需要14个页面的cache，达到大小后一起回收。

https://www.cnblogs.com/muahao/p/10109712.html

https://www.jianshu.com/p/7ab51b8a6368

https://zhuanlan.zhihu.com/p/118642121

#### 虚拟地址

分为页号和页偏移。

虚拟页号转换成物理页号的高位。

页偏移是物理页号的低位。

一般来说offset是12位，表示一个4kb的页表中的4096字节。



![截屏2020-07-21 下午10.38.12](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-21 下午10.38.12.png)

然后其中vpn又分为在cache中的多路相联的offset。

去tlb中查找。

使用tt作为索引找到某一行，tl找到具体的一行。

比如四路相联，就需要两位。

![截屏2020-07-21 下午10.40.38](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-21 下午10.40.38.png)

如果page fault了之后就去page table中查找。

![截屏2020-07-21 下午10.43.10](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-21 下午10.43.10.png)

#### 所有处理器对内存访问时一样的



![截屏2020-07-21 下午10.50.45](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-21 下午10.50.45.png)

<img src="/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-21 下午10.51.30.png" alt="截屏2020-07-21 下午10.51.30" style="zoom:200%;" />

numa主要每个cpu分为local内存和远程的内存。

对本地访问更快

https://www.cnblogs.com/loyenwang/p/11523678.html

PFN（page frame number）和mem_map数组index的关系是线性的（有一个固定偏移，如果内存对应的物理地址等于0，那么PFN就是数组index）。

而对于FLATMEM来说，如果其管理的的物理内存本身是连续的还好说，如果不连续的话，那么中间一部分物理地址是没有对应的物理内存的，形象的说就像是一个个洞（hole），这会浪费mem_map数组本身占用的内存空间。

#### 不连续内存模型

我感觉其实就是每个cpu下的物理内存是连续的，但是cpu和cpu之间存在空洞。



![截屏2020-07-21 下午10.54.15](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-21 下午10.54.15.png)



然后现在由pfn找到每个cpu的node之下的，再通过弄的本身去查找。

就会比之前的复杂。

通常使用pfc高位bit找到对应的node。和页表管理方式差不多。

https://zhuanlan.zhihu.com/p/68346347

NUMA强调的是memory和processor的位置关系，和内存模型其实是没有关系的，只不过，由于同一node上的memory和processor有更紧密的耦合关系（访问更快），因此需要多个node来管理。

```c
#define __pfn_to_page(pfn)            \ 
({    unsigned long __pfn = (pfn);        \ 
    unsigned long __nid = arch_pfn_to_nid(__pfn);  \ 
    NODE_DATA(__nid)->node_mem_map + arch_local_page_offset(__pfn, __nid);\ 
})
```



#### nuca

非均匀缓存访问模型。

#### 稀疏内存模型

，但是memory hotplug的出现让原来完美的设计变得不完美了，因为即便是一个node中的mem_maps[]也有可能是不连续了。



整个连续的物理地址空间是按照一个section一个section来切断的，每一个section内部，其memory是连续的（即符合flat memory的特点），因此，mem_map的page数组依附于section结构（struct mem_section）而不是node结构了（struct pglist_data）。当然，无论哪一种memory model，都需要处理PFN和page之间的对应关系，只不过sparse memory多了一个section的概念，让转换变成了PFN<--->Section<--->page。



https://cloud.tencent.com/developer/article/1518174



主要切断了和cpu之间的连续

![截屏2020-07-21 下午11.06.21](/Users/jieyang/Library/Application Support/typora-user-images/截屏2020-07-21 下午11.06.21.png)